# SmartCap

Smart Cap is an assistant for visually impaired which narrates the description of scene by taking pictures from webcam.

Why:

There are about 285 million visually impaired people in the world. They are not able to experience the world the way we do. Smart cap aims to provide this missing experience for them. The system uses state of the art deep learning techniques from aws rekognition for image classification and tagging. 

What:

The smart cap aims bring the beautiful world as a narrative to the visually impaired. The narrative is generated by converting the scenes in front of them to text which describes the important objects in the scene. Examples of text include 'A group of people playing a game of football', 'yellow truck parked next to the car', a bowl of salad kept on table'. For the first prototype of the system, one line along with some keywords are played as an audio to the users but in the later versions a detailed description would be added as the feature.

How:

The architecture of the system includes Amazon Echo,Raspberry Pi and online computer vision API's. 

A webcam which is retrofitted into a regular cap is connected to the Dragonboard/Raspberry Pi. The code given here runs on Raspberry Pi. The function of the code is to capture the image from the webcam and send it to amazon rekognition for recognition task. The response is then inserted to DynamoDB. 
When the user asks Alexa to describe the scene, the Alexa Skills Kit triggers Amazon Lambda function to fetch the data from the database (DynamoDB). The correct text is the played as an audio on the Alexa device.


#Process to be followed for Raspbery pi after getting linux OS up and running

# Update the system
1. <pre>sudo apt-get update</pre>
2. <pre>sudo apt-get upgrade</pre>

# Get required libraries
3. <pre>sudo apt-get install python-pip</pre>
4. <pre>sudo apt-get install libopencv-dev python-opencv</pre>
5. <pre>pip install matplotlib</pre>



# AWS Dynamo DB
6. Login to your Amazon Console - https://console.aws.amazon.com/
7. create a new user in the users in the left side of the page and give it a name and click on it .
8. go to permissions->add permissions->attach policies directly ->search bar->add the below permissions
9. AWSLambda_FullAccess
10. AmazonRekognitionFullAccess
11. AmazonDynamoDBFullAccess
12. AmazonCloudWatchEvidentlyFullAccess
13. AlexaForBusinessFullAccess
14. AmazonS3FullAccess

15. go to policies->create policy ->policy editor->json
16.paste the below code in the json editor and save
17. <pre>
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": "dynamodb:UpdateItem",
            "Resource": "arn:aws:dynamodb:YOUR_REGION:YOUR_ACCOUNT_ID:table/YOUR_TABLE_NAME"
        }
    ]
}
</pre>

18. give the name visioncap to the policy and create the policy 
19. go to permissions and add permissions and search for the newly created policy visioncap will be there and add the permission
20.  now go to iam->users->user_name->create access key ->Application running outside AWS->next->create access key , copy the details of access key id  and secret access key

# Configure for AWS
21. <pre>pip install boto3</pre>
22. <pre>pip install awscli</pre>
23. <pre>sudo aws configure</pre> and use the credentials (from above step)

# Clone the code
24. <pre>git clone https://github.com/aravind0015/smartcap.git</pre>
25. open an account in the aws website

# dynamobd table creation and Amazon rekognition API 
26. Go to Services -> DynamoDb -> Create Table
27. Give table name (smartcap) and Primary partition key as guid (String). Click Done.
28. the rekognition will be automatically added to the functionality as we have already given the amazonrekognitionfullaccess in iam 



# AWS Lambda Function 
29. Login to your Amazon Console - https://console.aws.amazon.com/. Go to IAM roles, create a new role for lambda giving permissions to the dynamoDB.
30. Go to Services -> Lambda -> Create function -> Blueprints (seach for alexa and get the template related to color app). Select the role created in the previous step. 
31. Copy the code given in 'aws_dynamodb.py' to your lambda function
32. Change the table name(and/or region) in the code and the application id of the skill kit(get it from skills kit. it should look like amzn1.echo-sdk-ams.app.xxxx.xxxx)

# AWS Alexa Skills Kit  
33. Got to https://developer.amazon.com/edw/home.html#/skills  
34. Click on Add a new skill    
35. Skill Information - Custom Skills, Give name like 'Smart Cap'  
36. Go to interaction model and copy the code from aws_ask.json and paste it in Intent Schema  
37. From 'aws_ask_helper.txt' file use custom slot types and sample utterances  
38. Click save and make sure there are no errors  
39. In the configuration tab: In the Endpoint past your Amazon Resource Name (Go to your Amazon lambda function to find it, would be something like  arn:aws:lambda:us-east-1:xxxx:function:xxxx)  

# Install the Alexa app and smart cap skills
40. Install the Alexa app on your phone and login with your credential
41. Enable smartcap skills (or your own skills)

# When you are done with all the above steps
#Testing instructions
1. Speak to Amazon Echo - "Alexa start smart cap" (you should hear the response as: "Sure, You can ask me to describe the scene")
2. Speak to Amazon Echo - "Alexa ask smart cap" -wait- "describe the scene"" (you should hear the response as: "No data received from device in past one minute"). This makes sure that the Alexa skills kit and dynamoDb are working as expected.
3. Get the userId. Speak to Amazon Echo - "Alexa ask smart cap to get the user info" (you should hear a long code)
4. Open http://alexa.amazon.com/ and login
5. In the userId card, you would see a long string 
(note: do this in mobile for getting the user id)
6. Copy the userId and paste it in aws_dynamodb.py file
7. Make sure you have python 2.7.9 +. [Terminal] which python. [Terminal] python --version
8. Run camera_image.py: <pre>python camera_image.py</pre> (You should see the images in the same folder)
9. Run aws_rekognition.py: <pre>python aws_rekognition.py</pre> (You should see the results in the terminal)
10. Run aws_dynamodb.py: <pre>python aws_dynamosb.py</pre> (Note: this might require sudo access depending on if you used sudo while doing aws configure. It will tell you if update item succedded for dynamodb)
11. Alternatively, you can use the autorun script instead of step 9 and 10. <pre>sh autorun.sh</pre>
12. Speak to Amazon Echo - "Alexa start smart cap" - wait - "describe the scene". If everything went well, you should now hear some relevant to the image that was capture by the camera 

Example: 'I think it is a yellow truck going on the road and the keywords are road, car, trees, sky'










