# SmartCap

Smart Cap is an assistant for visually impaired which narrates the description of scene by taking pictures from webcam.

Why:

There are about 285 million visually impaired people in the world. They are not able to experience the world the way we do. Smart cap aims to provide this missing experience for them. The system uses state of the art deep learning techniques from aws rekognition for image classification and tagging. 

What:

The smart cap aims bring the beautiful world as a narrative to the visually impaired. The narrative is generated by converting the scenes in front of them to text which describes the important objects in the scene. Examples of text include 'A group of people playing a game of football', 'yellow truck parked next to the car', a bowl of salad kept on table'. For the first prototype of the system, one line along with some keywords are played as an audio to the users but in the later versions a detailed description would be added as the feature.

How:

The architecture of the system includes Amazon Echo,Raspberry Pi and online computer vision API's. 

A webcam which is retrofitted into a regular cap is connected to the Dragonboard/Raspberry Pi. The code given here runs on Raspberry Pi. The function of the code is to capture the image from the webcam and send it to amazon rekognition for recognition task. The response is then inserted to DynamoDB. 
When the user asks Alexa to describe the scene, the Alexa Skills Kit triggers Amazon Lambda function to fetch the data from the database (DynamoDB). The correct text is the played as an audio on the Alexa device.


#Process to be followed for Raspbery pi after getting linux OS up and running

# Update the system
1. <pre>sudo apt-get update</pre>
2. <pre>sudo apt-get upgrade</pre>

# Get required libraries
3. <pre>sudo apt-get install python-pip</pre>
4. <pre>sudo apt-get install libopencv-dev python-opencv</pre>
5. <pre>pip install matplotlib</pre>

# Configure for AWS
6. <pre>pip install boto3</pre>
7. <pre>pip install awscli</pre>
8. Go to https://console.aws.amazon.com/iam/
   a. Users -> <yourname> -> Security Credentials -> 'Create Access Key'
9. <pre>sudo aws configure</pre> and use the credentials (from above step)


# Clone the code
12. <pre>git clone https://github.com/aravind0015/smartcap.git</pre>
13. open an account in the aws website

# AWS Dynamo DB
14. Login to your Amazon Console - https://console.aws.amazon.com/
15. create a new user in the users in the left side of the page and give it a name and click on it .
16. go to permissions->add permissions->attach policies directly ->search bar->add the below permissions
17. AWSLambda_FullAccess
18. AmazonRekognitionFullAccess
19. AmazonDynamoDBFullAccess
20. AmazonCloudWatchEvidentlyFullAccess
21. AlexaForBusinessFullAccess
22. AmazonS3FullAccess

23. go to policies->create policy ->policy editor->json
24.paste the below code in the json editor and save
25. <pre>
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": "dynamodb:UpdateItem",
            "Resource": "arn:aws:dynamodb:YOUR_REGION:YOUR_ACCOUNT_ID:table/YOUR_TABLE_NAME"
        }
    ]
}
</pre>

25. give the name visioncap to the policy and create the policy 
26. go to permissions and add permissions and search for the newly created policy visioncap will be there and add the permission
27.  now go to iam->users->user_name->create access key ->Application running outside AWS->next->create access key , copy the details of access key id  and secret access key 
# dynamobd table creation and Amazon rekognition API 
28. Go to Services -> DynamoDb -> Create Table
29. Give table name (smartcap) and Primary partition key as guid (String). Click Done.
30. the rekognition will be automatically added to the functionality as we have already given the amazonrekognitionfullaccess in iam 



# AWS Lambda Function 
31. Login to your Amazon Console - https://console.aws.amazon.com/. Go to IAM roles, create a new role for lambda giving permissions to the dynamoDB.
32. Go to Services -> Lambda -> Create function -> Blueprints (seach for alexa and get the template related to color app). Select the role created in the previous step. 
33. Copy the code given in 'aws_dynamodb.py' to your lambda function
34. Change the table name(and/or region) in the code and the application id of the skill kit(get it from skills kit. it should look like amzn1.echo-sdk-ams.app.xxxx.xxxx)

# AWS Alexa Skills Kit  
35. Got to https://developer.amazon.com/edw/home.html#/skills  
36. Click on Add a new skill    
37. Skill Information - Custom Skills, Give name like 'Smart Cap'  
38. Go to interaction model and copy the code from aws_ask.json and paste it in Intent Schema  
39. From 'aws_ask_helper.txt' file use custom slot types and sample utterances  
40. Click save and make sure there are no errors  
41. In the configuration tab: In the Endpoint past your Amazon Resource Name (Go to your Amazon lambda function to find it, would be something like  arn:aws:lambda:us-east-1:xxxx:function:xxxx)  

# Install the Alexa app and smart cap skills
42. Install the Alexa app on your phone and login with your credential
43. Enable smartcap skills (or your own skills)

# When you are done with all the above steps
#Testing instructions
1. Speak to Amazon Echo - "Alexa start smart cap" (you should hear the response as: "Sure, You can ask me to describe the scene")
2. Speak to Amazon Echo - "Alexa ask smart cap" -wait- "describe the scene"" (you should hear the response as: "No data received from device in past one minute"). This makes sure that the Alexa skills kit and dynamoDb are working as expected.
3. Get the userId. Speak to Amazon Echo - "Alexa ask smart cap to get the user info" (you should hear a long code)
4. Open http://alexa.amazon.com/ and login
5. In the userId card, you would see a long string 
(note: do this in mobile for getting the user id)
6. Copy the userId and paste it in aws_dynamodb.py file
7. Make sure you have python 2.7.9 +. [Terminal] which python. [Terminal] python --version
8. Run camera_image.py: <pre>python camera_image.py</pre> (You should see the images in the same folder)
9. Run aws_rekognition.py: <pre>python aws_rekognition.py</pre> (You should see the results in the terminal)
10. Run aws_dynamodb.py: <pre>python aws_dynamosb.py</pre> (Note: this might require sudo access depending on if you used sudo while doing aws configure. It will tell you if update item succedded for dynamodb)
11. Alternatively, you can use the autorun script instead of step 9 and 10. <pre>sh autorun.sh</pre>
12. Speak to Amazon Echo - "Alexa start smart cap" - wait - "describe the scene". If everything went well, you should now hear some relevant to the image that was capture by the camera 

Example: 'I think it is a yellow truck going on the road and the keywords are road, car, trees, sky'










